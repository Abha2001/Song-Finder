# -*- coding: utf-8 -*-
"""SongFinderFinal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aD5Jdekd-4Zt7Idd-u104qZcqxl6o-sg

Song Finder: Find your songs with a prompt

Idea: Create an embedding for song lyrics, create an embedding for prompt of what song you want to hear. Find the closest embedding and return song name (and lyrics).

## Import Libraries
"""

import numpy as np
import pandas as pd
import os
import zipfile

from tqdm import tqdm
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.model_selection import train_test_split

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader

from transformers import AutoTokenizer, AutoModel

from pathlib import Path

"""## Load Data"""

zip_file_path = 'archive.zip'

with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall()

dataset_df = pd.DataFrame()
pathlist = Path('archive/csv').glob('*.csv')
for path in pathlist:
    dataset_df = pd.concat([dataset_df, pd.read_csv(path, index_col = 0)])
dataset_df

dataset_df.shape

"""## Data Preprocessing and Cleaning"""

dataset_df.drop(columns = ['Album', 'Year', 'Date'], inplace = True)
dataset_df = dataset_df.dropna()
dataset_df.reset_index(drop = True, inplace = True)
dataset_df.shape

"""## Load Model and Tokenizer"""

tokenizer = AutoTokenizer.from_pretrained('roberta-base')
model = AutoModel.from_pretrained('roberta-base')

model.config

"""## Summarize Lyrics as Embedding"""

def tokenize_samples(data_sample):
  input_tokens = tokenizer(data_sample, padding = True, truncation = True)
  return input_tokens

def model_inference(batch):
  input_tokens = tokenize_samples(batch[1])

  input_ids = torch.tensor(input_tokens['input_ids'], dtype = torch.long)
  attn_mask = torch.tensor(input_tokens['attention_mask'], dtype = torch.long)

  model_output = model(input_ids, attention_mask = attn_mask)

  return model_output.pooler_output.detach().numpy()

class LyricsDataset(Dataset):
  def __init__(self, df):
    self.name = df['Title']
    self.lyric = df['Lyric']

  def __len__(self):
    return len(self.name)

  def __getitem__(self, idx):
    return self.name[idx], self.lyric[idx]

dataset = LyricsDataset(dataset_df)

dataloader = DataLoader(dataset, batch_size = 8, shuffle = True)

next(iter(dataloader))

embeddings_list = []

for batch in tqdm(dataloader):
  embeddings_list.append(model_inference(batch))

embeddings = np.vstack(embeddings_list)
embeddings.shape

prompt = 'satirical song about haters'
prompt_tokens = tokenizer(prompt)
model_output = model(input_ids = torch.tensor(prompt_tokens['input_ids'], dtype = torch.long).reshape(1, -1), attention_mask = torch.tensor(prompt_tokens['attention_mask'], dtype = torch.long).reshape(1, -1))

sim_vector = cosine_similarity(embeddings, model_output.pooler_output.detach().numpy())
sim_vector.shape

top_3 = np.argsort(sim_vector)[:, -3:]
top_3

for i, index in enumerate(top_3):
  print(f'Song {i + 1}: {dataset_df.iloc[index, :]}')

